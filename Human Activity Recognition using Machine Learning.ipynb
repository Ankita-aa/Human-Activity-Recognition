{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93a0658f",
   "metadata": {},
   "source": [
    "# Importing Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc82bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from sklearn.manifold import TSNE\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score , confusion_matrix ,classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC ,SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier , GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7303169c",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33950bd8",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbbdb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list()\n",
    "with open(\"UCI_HAR_Dataset/features.txt\") as f:\n",
    "    features = [ line.split(\"\\n\")[0] for line in f.readlines()]\n",
    "print(len(features))\n",
    "features[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3394bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d345e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = pd.read_csv(\"UCI_HAR_Dataset/train/X_train.txt\", delim_whitespace = True , header = None , names= features)\n",
    "Xtrain[\"subject\"] = pd.read_csv(\"UCI_HAR_Dataset/train/subject_train.txt\" , header = None , squeeze = True)\n",
    "\n",
    "Ytrain = pd.read_csv(\"UCI_HAR_Dataset/train/Y_train.txt\" ,names = [\"Activity\"], header = None , squeeze = True)\n",
    "Ytrain_labels = Ytrain.map({1: 'WALKING', 2:'WALKING_UPSTAIRS',3:'WALKING_DOWNSTAIRS',\\\n",
    "                       4:'SITTING', 5:'STANDING',6:'LAYING'})\n",
    "\n",
    "Train = Xtrain\n",
    "Train[\"Activity\"] = Ytrain\n",
    "Train[\"Activity_name\"] = Ytrain_labels\n",
    "\n",
    "Train.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511f6698",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb7fc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = pd.read_csv(\"UCI_HAR_Dataset/test/X_test.txt\", delim_whitespace = True , header = None , names= features)\n",
    "Xtest[\"subject\"] = pd.read_csv(\"UCI_HAR_Dataset/test/subject_test.txt\" , header = None , squeeze = True)\n",
    "\n",
    "Ytest = pd.read_csv(\"UCI_HAR_Dataset/test/Y_test.txt\" ,names = [\"Activity\"], header = None , squeeze = True)\n",
    "Ytest_labels = Ytest.map({1: 'WALKING', 2:'WALKING_UPSTAIRS',3:'WALKING_DOWNSTAIRS',\\\n",
    "                       4:'SITTING', 5:'STANDING',6:'LAYING'})\n",
    "\n",
    "Test = Xtest\n",
    "Test[\"Activity\"] = Ytest\n",
    "Test[\"Activity_name\"] = Ytest_labels\n",
    "\n",
    "Test.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f014c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7486eddf",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e15d787",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63efeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"No. of duplicated values in Train :\",sum(Train.duplicated()))\n",
    "print(\"No. of duplicated values in Test :\",sum(Test.duplicated()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ad2f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Np. of Nan or null values in Train :\" , Train.isnull().values.sum())\n",
    "print(\"No. of Nan or null values in Test :\", Test.isnull().values.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3027b9",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1fc8e9",
   "metadata": {},
   "source": [
    "# Checking data imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfc1c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style = \"darkgrid\")\n",
    "plt.figure(figsize = (16,8))\n",
    "plt.title(\"Data provided by each user\",fontsize = 20)\n",
    "sns.countplot(x = \"subject\",hue = \"Activity_name\",data = Train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893c71d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "plt.title(\"No. of data per activity\",fontsize = 20)\n",
    "sns.countplot(x = Train.Activity_name)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e629250c",
   "metadata": {},
   "source": [
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb48dd3",
   "metadata": {},
   "source": [
    "# Changing columns name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6661eaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = Train.columns\n",
    "\n",
    "# Removing '()' from column names\n",
    "columns = columns.str.replace('[()]','')\n",
    "columns = columns.str.replace('[-]', '')\n",
    "columns = columns.str.replace('[,]','')\n",
    "\n",
    "Train.columns = columns\n",
    "Test.columns = columns\n",
    "\n",
    "Test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7579e371",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in columns:\n",
    "    if i.find(\"tBodyAccMagmean\")>= 0 :\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bcd25a",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c27e529",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abadb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.FacetGrid(Train,hue = \"Activity_name\",height = 6 , aspect = 2)\\\n",
    ".map(sns.distplot,'201 tBodyAccMagmean',hist = False)\\\n",
    ".add_legend()\n",
    "\n",
    "plt.annotate(\"Stationary Activities\",xy = (-0.9,15),\\\n",
    "             xytext = (-0.8,15),va = \"center\",ha = \"left\",size = 20,\\\n",
    "             arrowprops = dict(arrowstyle = \"simple\",connectionstyle = \"arc3,rad= 0.1\"))\n",
    "\n",
    "plt.annotate(\"Moving Activities\",xy = (0,3),xytext = (0.3,6),\\\n",
    "            va=\"center\",ha = \"left\",size = 20, arrowprops = dict(arrowstyle= \"simple\",connectionstyle = \"arc3,rad = 0.1\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb3b761",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c332dbb",
   "metadata": {},
   "source": [
    "# TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b89e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tsne = Train.drop([\"subject\",\"Activity\",\"Activity_name\"],axis = 1)\n",
    "y_tsne = Train.Activity_name\n",
    "\n",
    "print(x_tsne.shape , y_tsne.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f46955f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def perform_tsne(xdata , ydata , perplexity , n_iter = 2000):\n",
    "    for i in perplexity:\n",
    "        print(\"Performing TSNE with perplexity\",i)\n",
    "        tsne = TSNE(perplexity = i).fit_transform(xdata)\n",
    "        \n",
    "        print(\"Plotting visualisation of TSNE\")\n",
    "        dataset = pd.DataFrame(tsne,columns = [\"x\",\"y\"])\n",
    "        dataset[\"Activity\"] = ydata\n",
    "        sns.FacetGrid(dataset,hue = \"Activity\",height = 7).map(plt.scatter,\"x\",\"y\").add_legend()\n",
    "        plt.savefig(\"TSNE with perplexity\" + str(i))\n",
    "        plt.show()\n",
    " \n",
    "perform_tsne(x_tsne,y_tsne,[20,30,40,50],3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cdf085",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d871b484",
   "metadata": {},
   "source": [
    "# ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d60236",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = Train.drop([\"subject\",\"Activity\",\"Activity_name\"],axis = 1)\n",
    "Ytrain = Train.Activity\n",
    "\n",
    "Xtest = Test.drop([\"subject\",\"Activity\",\"Activity_name\"] , axis = 1)\n",
    "Ytest = Test.Activity\n",
    "\n",
    "Activity_labels = Ytrain_labels\n",
    "\n",
    "Scaler = StandardScaler()\n",
    "\n",
    "Xtrain = Scaler.fit_transform(Xtrain)\n",
    "Xtest = Scaler.fit_transform(Xtest)\n",
    "\n",
    "print(Xtrain.shape , Ytrain.shape)\n",
    "print(Xtest.shape , Ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d35f5b",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37051ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_run(model,xtrain,ytrain,xtest,ytest):\n",
    "    model = model.fit(xtrain,ytrain)\n",
    "    ypred = model.predict(xtest)\n",
    "    print(\"\\n\\n\\n\")\n",
    "    print(\"Best Estimator\\n\")\n",
    "    print(model.best_estimator_)\n",
    "    print(\"\\n\\n\\n\")\n",
    "    print(\"Best Parameter\\n\")\n",
    "    print(model.best_params_)\n",
    "    print(\"\\n\\n\\n\")\n",
    "    print(\"Best Score\\n\")\n",
    "    print(model.best_score_)\n",
    "    print(\"\\n\\n\\n\")\n",
    "    print(\"Accuracy score\",accuracy_score(ytest, ypred))\n",
    "    print(\"\\n\\n\\n\")\n",
    "    print(\"Confusion matrix\\n\", confusion_matrix(ytest,ypred))\n",
    "    print(\"\\n\\n\\n\")\n",
    "    print(\"Classfication report\\n\")\n",
    "    print(classification_report(ytest,ypred))\n",
    "    print(\"\\n\\n\\n\")\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70bfbea",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0774a58d",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e5fe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter = 1000)\n",
    "params = {\"C\" : [0.01,0.1,1,10,20,30],\"penalty\" : [\"l1\",\"l2\"]}\n",
    "\n",
    "grid_search = GridSearchCV(model,param_grid = params , cv =3,verbose = 1 , n_jobs = - 1)\n",
    "\n",
    "model_run(grid_search,Xtrain,Ytrain,Xtest,Ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aef033",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62871649",
   "metadata": {},
   "source": [
    "# Linear SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8eeb12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearSVC(max_iter = 2000,tol= 0.00005)\n",
    "params = {\"C\": [0.01,0.1,1,10,20,30],\"penalty\":[\"l1\",\"l2\"]}\n",
    "\n",
    "grid_search = GridSearchCV(model,param_grid = params ,cv =3 ,verbose = 1 , n_jobs = -1)\n",
    "\n",
    "model_run(grid_search , Xtrain ,Ytrain, Xtest , Ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccb95b1",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e5d595",
   "metadata": {},
   "source": [
    "# Kernel SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d77c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel = \"rbf\")\n",
    "params = { \"C\": [0.1,1,2,4] , \"gamma\" :[0.0078,0.01,1,1.125,2]}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid = params , cv= 3 , verbose = 1 , n_jobs = -1)\n",
    "model_run(grid_search , Xtrain , Ytrain , Xtest , Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20b787b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#May improve more\n",
    "\n",
    "model = SVC(kernel = \"rbf\")\n",
    "params = { \"C\": [1.8,2,2.2] , \"gamma\" :[0.001,0.003,0.006]}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid = params , cv= 3 , verbose = 1 , n_jobs = -1)\n",
    "model_run(grid_search , Xtrain , Ytrain , Xtest , Ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6b1253",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85adea19",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794e6da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "params = {\"max_depth\" : np.arange(3,8)}\n",
    "\n",
    "grid_search = GridSearchCV(model,param_grid = params, n_jobs = -1)\n",
    "model_run(grid_search , Xtrain , Ytrain , Xtest , Ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1cab53",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10119197",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e002ac8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_jobs = -1)\n",
    "params = {\"n_estimators\" : np.arange(100,300,20)  , \"max_depth\" : np.arange(3,15,2) }\n",
    "\n",
    "grid_search = GridSearchCV(model,param_grid = params)\n",
    "model_run(grid_search , Xtrain , Ytrain , Xtest , Ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d8dd14",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3aa73f",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb44d4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "params = {\"n_estimators\" : np.arange(130,170,10)  , \"max_depth\" : np.arange(5,8,1) }\n",
    "\n",
    "grid_search = GridSearchCV(model,param_grid = params,n_jobs = -1)\n",
    "model_run(grid_search , Xtrain , Ytrain , Xtest , Ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f44ac62",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b85793b",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f23f642",
   "metadata": {},
   "source": [
    "Logistic Regression , Linear SVC and Kernel SVC will be most accurate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2c6f81",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
